# Course Resources and References

## Textbooks

### Primary References
1. **Digital Image Processing** by Gonzalez & Woods (4th Edition)
   - Classic computer vision textbook
   - Excellent coverage of classical CV techniques
   - Available in library

2. **Computer Vision: Algorithms and Applications** by Richard Szeliski
   - Free online: [http://szeliski.org/Book/](http://szeliski.org/Book/)
   - Modern comprehensive coverage
   - Great for geometry and 3D vision

3. **Multiple View Geometry** (MIT Vision Book)
   - Available at: [https://visionbook.mit.edu](https://visionbook.mit.edu)
   - Excellent for geometric computer vision
   - Mathematical but accessible

### Supplementary References
4. **Deep Learning** by Goodfellow, Bengio, and Courville
   - Free online: [https://www.deeplearningbook.org/](https://www.deeplearningbook.org/)
   - Comprehensive deep learning theory

5. **Computer Vision: A Modern Approach** by Forsyth and Ponce
   - Another classic textbook
   - Good alternative perspective

## Online Courses

### Highly Recommended
- **CS231n: Convolutional Neural Networks for Visual Recognition** (Stanford)
  - [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
  - Video lectures, notes, and assignments available
  - Excellent for deep learning basics

- **First Principles of Computer Vision** (Columbia)
  - YouTube channel with detailed lectures
  - Great for fundamentals

### Additional MOOCs
- **Coursera: Introduction to Computer Vision** (Georgia Tech)
- **Deep Learning Specialization** (deeplearning.ai)
- **Fast.ai Practical Deep Learning for Coders**

## Documentation and Tutorials

### PyTorch
- **Official Documentation:** [https://pytorch.org/docs/](https://pytorch.org/docs/)
- **Tutorials:** [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)
- **PyTorch Lightning:** [https://lightning.ai/](https://lightning.ai/)

### OpenCV
- **Official Tutorials:** [https://docs.opencv.org/master/d9/df8/tutorial_root.html](https://docs.opencv.org/master/d9/df8/tutorial_root.html)
- **Learn OpenCV:** [https://learnopencv.com/](https://learnopencv.com/)

### Other Libraries
- **scikit-image:** [https://scikit-image.org/](https://scikit-image.org/)
- **Albumentations:** [https://albumentations.ai/](https://albumentations.ai/)
- **MMDetection:** [https://github.com/open-mmlab/mmdetection](https://github.com/open-mmlab/mmdetection)

## Datasets

### General Purpose
- **ImageNet:** [https://image-net.org/](https://image-net.org/)
  - 14M images, 20K categories
  - Standard benchmark for classification

- **COCO (Common Objects in Context):** [https://cocodataset.org/](https://cocodataset.org/)
  - Detection, segmentation, captioning
  - 330K images, 80 categories

- **Open Images:** [https://storage.googleapis.com/openimages/web/index.html](https://storage.googleapis.com/openimages/web/index.html)
  - 9M images, 600 categories
  - More diverse than ImageNet

### Specialized Datasets

**Faces:**
- CelebA: Celebrity faces (200K images)
- VGGFace2: Face recognition (3.3M images)
- WIDER Face: Face detection dataset

**Medical:**
- ChestX-ray14: Chest X-ray pathology
- ISIC: Skin lesion images
- BraTS: Brain tumor segmentation

**Scenes:**
- Places365: Scene recognition
- MIT Indoor: Indoor scenes
- SUN Database: Scene understanding

**Autonomous Driving:**
- KITTI: Stereo, flow, depth, detection
- Cityscapes: Urban street scenes
- nuScenes: Full autonomous driving dataset

**Other:**
- Fashion-MNIST: Fashion items (grayscale)
- Food-101: Food images
- Oxford Pets: 37 pet breeds

### Dataset Search
- **Google Dataset Search:** [https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com/)
- **Kaggle Datasets:** [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
- **Papers with Code Datasets:** [https://paperswithcode.com/datasets](https://paperswithcode.com/datasets)
- **Roboflow Universe:** [https://universe.roboflow.com/](https://universe.roboflow.com/)

## Software and Tools

### Development Environments
- **Jupyter Lab/Notebook**
- **Google Colab:** Free GPU access
- **Kaggle Kernels:** Free GPU/TPU access
- **VS Code:** With Python extension

### Annotation Tools
- **LabelImg:** Bounding box annotation
- **Labelme:** Polygon annotation
- **CVAT:** Comprehensive annotation tool
- **VGG Image Annotator (VIA):** Web-based

### Visualization
- **TensorBoard:** Training visualization
- **Weights & Biases:** Experiment tracking
- **Netron:** Neural network visualizer

## Key Papers

### Classic Computer Vision
1. **SIFT:** "Distinctive Image Features from Scale-Invariant Keypoints" (Lowe, 2004)
2. **HOG:** "Histograms of Oriented Gradients for Human Detection" (Dalal & Triggs, 2005)
3. **Canny Edge Detector:** "A Computational Approach to Edge Detection" (Canny, 1986)

### Deep Learning Milestones
4. **AlexNet:** "ImageNet Classification with Deep Convolutional Neural Networks" (Krizhevsky et al., 2012)
5. **VGGNet:** "Very Deep Convolutional Networks for Large-Scale Image Recognition" (Simonyan & Zisserman, 2014)
6. **ResNet:** "Deep Residual Learning for Image Recognition" (He et al., 2015)
7. **Batch Normalization:** "Batch Normalization: Accelerating Deep Network Training" (Ioffe & Szegedy, 2015)

### Modern Architectures
8. **Vision Transformer (ViT):** "An Image is Worth 16x16 Words" (Dosovitskiy et al., 2020)
9. **EfficientNet:** "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks" (Tan & Le, 2019)
10. **CLIP:** "Learning Transferable Visual Models From Natural Language Supervision" (Radford et al., 2021)

### Object Detection
11. **R-CNN:** "Rich Feature Hierarchies for Accurate Object Detection" (Girshick et al., 2014)
12. **YOLO:** "You Only Look Once: Unified, Real-Time Object Detection" (Redmon et al., 2016)
13. **Mask R-CNN:** "Mask R-CNN" (He et al., 2017)

### Segmentation
14. **FCN:** "Fully Convolutional Networks for Semantic Segmentation" (Long et al., 2015)
15. **U-Net:** "U-Net: Convolutional Networks for Biomedical Image Segmentation" (Ronneberger et al., 2015)

## Blogs and Communities

### Blogs
- **Andrej Karpathy's Blog:** [http://karpathy.github.io/](http://karpathy.github.io/)
- **Colah's Blog:** [https://colah.github.io/](https://colah.github.io/)
- **Distill.pub:** [https://distill.pub/](https://distill.pub/)
- **PyImageSearch:** [https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)
- **Machine Learning Mastery:** [https://machinelearningmastery.com/](https://machinelearningmastery.com/)

### Communities
- **Reddit:**
  - r/computervision
  - r/MachineLearning
  - r/learnmachinelearning

- **Stack Overflow:** Computer vision tag
- **Cross Validated:** Statistics and ML Stack Exchange
- **AI Alignment Forum**

### Conferences
- **CVPR:** Computer Vision and Pattern Recognition
- **ICCV:** International Conference on Computer Vision
- **ECCV:** European Conference on Computer Vision
- **NeurIPS:** Neural Information Processing Systems
- **ICML:** International Conference on Machine Learning

## YouTube Channels

- **Two Minute Papers:** Latest research summaries
- **Yannic Kilcher:** Paper reviews and discussions
- **sentdex:** Python and ML tutorials
- **3Blue1Brown:** Mathematical visualizations
- **StatQuest:** Statistics and ML concepts

## GitHub Repositories

### Awesome Lists
- **Awesome Computer Vision:** [https://github.com/jbhuang0604/awesome-computer-vision](https://github.com/jbhuang0604/awesome-computer-vision)
- **Awesome Deep Vision:** [https://github.com/kjw0612/awesome-deep-vision](https://github.com/kjw0612/awesome-deep-vision)

### Implementations
- **PyTorch Image Models (timm):** [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models)
- **MMDetection:** State-of-the-art detection
- **Detectron2:** Facebook's detection platform
- **YOLOv5:** Popular object detection

### Learning Resources
- **Dive into Deep Learning:** [https://d2l.ai/](https://d2l.ai/)
- **The Hundred-Page Machine Learning Book**
- **Deep Learning with PyTorch:** Book code repo

## Computational Resources

### Free GPU Options
1. **Google Colab**
   - 12-15GB RAM
   - Tesla T4 or K80 GPU
   - 12-hour session limit

2. **Kaggle Kernels**
   - 16GB RAM
   - P100 GPU or TPU
   - 9-hour session limit

3. **Paperspace Gradient**
   - Free tier available
   - Various GPU options

### Academic Credits
- **AWS Educate**
- **Google Cloud for Education**
- **Azure for Students**

### Local Setup
- **CUDA Toolkit:** For NVIDIA GPUs
- **cuDNN:** Deep learning primitives
- **Docker:** For containerization

## Keeping Up with Research

### Preprint Servers
- **arXiv.org:** Computer vision papers (cs.CV)
- **Papers with Code:** Papers + code implementations

### Newsletters
- **Import AI:** Weekly AI newsletter
- **The Batch:** deeplearning.ai newsletter
- **ML News:** Machine learning news

### Twitter Accounts to Follow
- @karpathy (Andrej Karpathy)
- @ylecun (Yann LeCun)
- @goodfellow_ian (Ian Goodfellow)
- @fchollet (Fran√ßois Chollet)
- @hardmaru (David Ha)

## Recommended Reading Path

**For Beginners:**
1. Start with CS231n notes and lectures
2. Practice with PyTorch tutorials
3. Implement basic algorithms from scratch
4. Read Gonzalez & Woods selected chapters

**For Intermediate:**
1. Deep Learning book (Goodfellow et al.)
2. Computer Vision (Szeliski)
3. Implement recent papers
4. Participate in Kaggle competitions

**For Advanced:**
1. Read latest conference papers
2. Reproduce SOTA results
3. Contribute to open source
4. Work on novel research problems

## Office Hours and Support

- **Instructor Office Hours:** TBD
- **TA Office Hours:** TBD
- **Online Forum:** [Link to course forum]
- **Email:** Use for private matters only

## Tips for Success

1. **Read actively:** Code along with tutorials
2. **Experiment:** Change hyperparameters, try variations
3. **Visualize:** Always visualize your data and results
4. **Debug systematically:** Check shapes, values, gradients
5. **Start simple:** Get a basic version working first
6. **Ask questions:** No question is too basic
7. **Collaborate:** Learn from your peers
8. **Build projects:** Apply concepts to real problems
9. **Stay current:** Follow latest developments
10. **Have fun:** Enjoy the learning process!

---

*This is a living document - suggestions for additions are welcome!*
